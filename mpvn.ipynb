{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from mpvn.data.grad.lit_data_module import LightningGradDataModule\n",
    "from mpvn.metric import WordErrorRate\n",
    "from mpvn.model import ConformerLSTMModel\n",
    "\n",
    "from mpvn.configs import DictConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m num_devices \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      9\u001b[0m data_module \u001b[39m=\u001b[39m LightningLibriSpeechDataModule(configs)\n\u001b[0;32m---> 10\u001b[0m vocab \u001b[39m=\u001b[39m data_module\u001b[39m.\u001b[39;49mprepare_data(configs\u001b[39m.\u001b[39;49mdataset_download, configs\u001b[39m.\u001b[39;49mvocab_size)\n\u001b[1;32m     11\u001b[0m data_module\u001b[39m.\u001b[39msetup(vocab\u001b[39m=\u001b[39mvocab)\n\u001b[1;32m     13\u001b[0m model \u001b[39m=\u001b[39m ConformerLSTMModel(configs\u001b[39m=\u001b[39mconfigs,\n\u001b[1;32m     14\u001b[0m                             num_classes\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(vocab),\n\u001b[1;32m     15\u001b[0m                             vocab\u001b[39m=\u001b[39mvocab,\n\u001b[1;32m     16\u001b[0m                             cer_metric\u001b[39m=\u001b[39mCharacterErrorRate(vocab))\n",
      "File \u001b[0;32m/media/wicii/DDH/class/graduation_project/mpvn/mpvn/data/librispeech/lit_data_module.py:206\u001b[0m, in \u001b[0;36mLightningLibriSpeechDataModule.prepare_data\u001b[0;34m(self, download, vocab_size)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39mPrepare librispeech data\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39m    None\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39mif\u001b[39;00m download:\n\u001b[0;32m--> 206\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_librispeech()\n\u001b[1;32m    207\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_manifest_files(vocab_size)\n\u001b[1;32m    208\u001b[0m \u001b[39mreturn\u001b[39;00m LibriSpeechVocabulary(\u001b[39m\"\u001b[39m\u001b[39mtokenizer.model\u001b[39m\u001b[39m\"\u001b[39m, vocab_size)\n",
      "File \u001b[0;32m/media/wicii/DDH/class/graduation_project/mpvn/mpvn/data/librispeech/lit_data_module.py:152\u001b[0m, in \u001b[0;36mLightningLibriSpeechDataModule._download_librispeech\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLibrispeech-\u001b[39m\u001b[39m{\u001b[39;00mpart\u001b[39m}\u001b[39;00m\u001b[39m download..\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    151\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mbase_url\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mpart\u001b[39m}\u001b[39;00m\u001b[39m.tar.gz\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 152\u001b[0m wget\u001b[39m.\u001b[39;49mdownload(url, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_path)\n\u001b[1;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUn-tarring archive \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_path\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mpart\u001b[39m}\u001b[39;00m\u001b[39m.tar.gz\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    155\u001b[0m tar \u001b[39m=\u001b[39m tarfile\u001b[39m.\u001b[39mopen(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_path\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mpart\u001b[39m}\u001b[39;00m\u001b[39m.tar.gz\u001b[39m\u001b[39m\"\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mr:gz\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/grad/lib/python3.8/site-packages/wget.py:526\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(url, out, bar)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    525\u001b[0m     binurl \u001b[39m=\u001b[39m url\n\u001b[0;32m--> 526\u001b[0m (tmpfile, headers) \u001b[39m=\u001b[39m ulib\u001b[39m.\u001b[39;49murlretrieve(binurl, tmpfile, callback)\n\u001b[1;32m    527\u001b[0m filename \u001b[39m=\u001b[39m detect_filename(url, out, headers)\n\u001b[1;32m    528\u001b[0m \u001b[39mif\u001b[39;00m outdir:\n",
      "File \u001b[0;32m~/miniconda3/envs/grad/lib/python3.8/urllib/request.py:276\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    273\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[1;32m    275\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     block \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39;49mread(bs)\n\u001b[1;32m    277\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m block:\n\u001b[1;32m    278\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/grad/lib/python3.8/http/client.py:459\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     \u001b[39m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     b \u001b[39m=\u001b[39m \u001b[39mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 459\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b)[:n]\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    461\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[39m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[39m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/grad/lib/python3.8/http/client.py:503\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    498\u001b[0m         b \u001b[39m=\u001b[39m \u001b[39mmemoryview\u001b[39m(b)[\u001b[39m0\u001b[39m:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength]\n\u001b[1;32m    500\u001b[0m \u001b[39m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[39m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[39m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m n \u001b[39mand\u001b[39;00m b:\n\u001b[1;32m    505\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/miniconda3/envs/grad/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "configs = DictConfig()\n",
    "\n",
    "pl.seed_everything(configs.seed)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logger = logger = TensorBoardLogger(\"tensorboard\", name=\"Pronunciation for Vietnamese\")\n",
    "num_devices = 1\n",
    "\n",
    "data_module = LightningGradDataModule(configs)\n",
    "vocab = data_module.get_vocab(configs.dataset_download, configs.vocab_size)\n",
    "data_module.setup(vocab=vocab)\n",
    "\n",
    "model = ConformerLSTMModel(configs=configs,\n",
    "                            num_classes=len(vocab),\n",
    "                            vocab=vocab,\n",
    "                            per_metric=WordErrorRate(vocab))\n",
    "\n",
    "trainer = pl.Trainer(precision=configs.precision,\n",
    "                        accelerator=configs.accelerator,\n",
    "                        gpus=num_devices,\n",
    "                        accumulate_grad_batches=configs.accumulate_grad_batches,\n",
    "                        amp_backend=configs.amp_backend,\n",
    "                        auto_select_gpus=configs.auto_select_gpus,\n",
    "                        check_val_every_n_epoch=configs.check_val_every_n_epoch,\n",
    "                        gradient_clip_val=configs.gradient_clip_val,\n",
    "                        logger=logger,\n",
    "                        max_epochs=configs.max_epochs)\n",
    "\n",
    "trainer.fit(model, data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('grad')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b1a50cc58c14d82ff378b4491fa094aec266868d23c7ca7976fe8f9a4aaf20a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
